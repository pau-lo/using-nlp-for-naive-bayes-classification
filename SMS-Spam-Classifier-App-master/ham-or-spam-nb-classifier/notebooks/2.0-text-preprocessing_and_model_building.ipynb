{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS Spam Classifier: Naive Bayes ML Algorithm\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import os\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer,\n",
    "    TfidfVectorizer\n",
    ")\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n"
   ]
  },
  {
   "source": [
    "##  Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   label                                            message  length\n",
       "0      0  Go until jurong point, crazy.. Available only ...     111\n",
       "1      0                      Ok lar... Joking wif u oni...      29\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3      0  U dun say so early hor... U c already then say...      49\n",
       "4      0  Nah I don't think he goes to usf, he lives aro...      61"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>111</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>155</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>61</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# load data\n",
    "path = '~/workspace/data-science/my-projects/SMS-Spam-Classifier-App-master/ham-or-spam-nb-classifier/data/processed/'\n",
    "\n",
    "df = pd.read_csv(path + 'spam_processed.csv', delimiter=',', encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing and Feature Generation using Bag of Words\n",
    "---\n",
    "\n",
    "All the messages part in our data are in text form. Thus, our Naive Bayes algorithm won't work if this is not taking care of.  In other words, we need to represent our text in to a vector form that our algorithm will be able to use for classification purposes.  This is usually known as converting a **corpus** into a **vector** format.\n",
    "\n",
    "\n",
    "We will use **CountVectorizer** from scikit-learn to convert a collection of text documents into a matrix of token counts.\n",
    "\n",
    "+ CountVectorizer  \n",
    "+ TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['label', 'message', 'length'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "source": [
    "If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data.\n",
    "\n",
    "We need to convert a corpus to a vector format. The simplest is the the bag-of-words approach, where each unique word in a text will be represented by one number. Let's use this by using scikit-learn's CountVectorizer and nltk RegexTokenizer to remove unwanted elements from our data like symbols and numbers we might it missed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokinize message just in case we missed some numbers or other chars\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "# generate document term matrix by using scikit-learn's CountVectorizer()\n",
    "# Return a function that splits a string into a sequence of tokens\n",
    "cv = CountVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    tokenizer= token.tokenize\n",
    ")"
   ]
  },
  {
   "source": [
    "### Split data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(df['message'])\n",
    "y= df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "s', 'salesman', 'salmon', 'salon', 'salt', 'sam', 'samachara', 'samantha', 'sambar', 'samus', 'sandiago', 'sane', 'sang', 'sankatmochan', 'sankranti', 'santa', 'santacalling', 'sao', 'sapna', 'sar', 'sara', 'sarasota', 'sarcasm', 'sarcastic', 'saristar', 'sariyag', 'sary', 'sashimi', 'sat', 'satanic', 'sathy', 'sathya', 'satisfied', 'satisfy', 'satsgettin', 'saturday', 'saucy', 'savamob', 'save', 'saved', 'saves', 'savings', 'saw', 'say', 'sayin', 'saying', 'says', 'sayy', 'sc', 'scallies', 'scammers', 'scarcasim', 'scared', 'scary', 'scenario', 'scenery', 'sch', 'schedule', 'school', 'schools', 'science', 'scold', 'scool', 'scorable', 'score', 'scores', 'scoring', 'scotch', 'scotland', 'scotsman', 'scouse', 'scraped', 'scrappy', 'scratches', 'scratching', 'scream', 'screamed', 'screaming', 'screen', 'screwd', 'scrounge', 'scrumptious', 'sculpture', 'sd', 'sday', 'sdryb8i', 'se', 'sea', 'search', 'searching', 'season', 'seat', 'sec', 'second', 'secondary', 'seconds', 'secret', 'secretary', 'secretly', 'secrets', 'secs', 'section', 'sections', 'secure', 'secured', 'sed', 'seeds', 'seeing', 'seekers', 'seeking', 'seen', 'sef', 'seh', 'sehwag', 'seing', 'select', 'selected', 'selection', 'self', 'selfindependence', 'selfish', 'selflessness', 'sell', 'selling', 'sells', 'sem', 'semester', 'semi', 'semiobscure', 'sen', 'send', 'sender', 'sending', 'sends', 'senor', 'senrd', 'sense', 'senses', 'sensible', 'sensitive', 'sent', 'sentence', 'senthil', 'sentiment', 'seperated', 'sept', 'september', 'serena', 'series', 'seriously', 'served', 'server', 'service', 'services', 'serving', 'servs', 'set', 'setting', 'settings', 'settle', 'settled', 'settling', 'seven', 'seventeen', 'sex', 'sexiest', 'sextextuk', 'sexual', 'sexy', 'sexychat', 'sez', 'sf', 'sg', 'sh', 'sha', 'shade', 'shadow', 'shag', 'shagged', 'shah', 'shahjahan', 'shakara', 'shake', 'shakespeare', 'shaking', 'shall', 'shame', 'shampain', 'shangela', 'shanghai', 'shanil', 'shant', 'shaping', 'share', 'shared', 'sharing', 'shattered', 'shaved', 'shb', 'shd', 'sheet', 'sheets', 'sheffield', 'shelf', 'shell', 'shelves', 'sherawat', 'shes', 'shesil', 'shhhhh', 'shifad', 'shijas', 'shijutta', 'shinco', 'shindig', 'shining', 'shiny', 'ship', 'shipped', 'shipping', 'shirt', 'shirts', 'shit', 'shite', 'shitin', 'shitinnit', 'shitload', 'shitstorm', 'shivratri', 'shld', 'shldxxxx', 'shock', 'shocking', 'shoes', 'shola', 'shoot', 'shop', 'shoppin', 'shopping', 'shoranur', 'shore', 'short', 'shortage', 'shortbreaks', 'shortcode', 'shorter', 'shortly', 'shorts', 'shot', 'shoul', 'shoulders', 'shouldn', 'shouted', 'shouting', 'shove', 'shoving', 'showed', 'shower', 'showered', 'showers', 'showing', 'showr', 'showrooms', 'shows', 'shracomorsglsuplt', 'shrek', 'shrink', 'shrub', 'shsex', 'shu', 'shud', 'shuhui', 'shun', 'shut', 'shy', 'si', 'sian', 'sib', 'sic', 'sick', 'sickness', 'sigh', 'sighs', 'sight', 'sign', 'signal', 'significance', 'significant', 'signin', 'signing', 'siguviri', 'silence', 'silent', 'silently', 'silly', 'silver', 'sim', 'simonwatson5120', 'simple', 'simpler', 'simply', 'simpsons', 'simulate', 'sinco', 'sindu', 'sing', 'singapore', 'singing', 'single', 'singles', 'sink', 'sip', 'sipix', 'sips', 'sir', 'sirji', 'sis', 'sister', 'sisters', 'sit', 'site', 'sitll', 'sitter', 'sittin', 'sitting', 'situation', 'situations', 'siva', 'size', 'sized', 'sk3', 'sk38xh', 'skateboarding', 'skilgme', 'skillgame', 'skills', 'skinny', 'skins', 'skint', 'skip', 'skirt', 'sky', 'skye', 'skype', 'skyped', 'skyving', 'slaaaaave', 'slacking', 'slap', 'slave', 'sleep', 'sleepin', 'sleeping', 'sleepingwith', 'sleeps', 'sleepwell', 'sleepy', 'slept', 'slice', 'slices', 'slide', 'sliding', 'slightly', 'slip', 'slippers', 'slippery', 'slo', 'slob', 'slots', 'slovely', 'slow', 'slower', 'slowing', 'slowly', 'slp', 'slurp', 'smacks', 'small', 'smaller', 'smart', 'smartcall', 'smarter', 'smash', 'smashed', 'smear', 'smell', 'smells', 'smeone', 'smidgin', 'smile', 'smiled', 'smiles', 'smiley', 'smiling', 'smith', 'smoke', 'smoked', 'smokes', 'smokin', 'smoking', 'smoothly', 'sms', 'smsco', 'smsing', 'smsrewards', 'smsservices', 'smth', 'sn', 'snake', 'snap', 'snappy', 'snatch', 'snd', 'sneham', 'snickering', 'snogs', 'snoring', 'snot', 'snow', 'snowball', 'snowboarding', 'snowman', 'snuggles', 'soc', 'sochte', 'social', 'sofa', 'soft', 'software', 'soil', 'soiree', 'sol', 'soladha', 'sold', 'solihull', 'solve', 'solved', 'some1', 'somebody', 'someday', 'someonone', 'someplace', 'somerset', 'sometext', 'somethin', 'sometme', 'somewhat', 'somewheresomeone', 'somewhr', 'somone', 'somtimes', 'sonathaya', 'sonetimes', 'song', 'songs', 'sony', 'sonyericsson', 'soo', 'soon', 'sooner', 'soonlots', 'sooo', 'soooo', 'sooooo', 'sophas', 'sore', 'sorrow', 'sorrows', 'sorry', 'sort', 'sorta', 'sorted', 'sorting', 'sorts', 'sory', 'soryda', 'sos', 'soul', 'sound', 'sounding', 'sounds', 'soundtrack', 'soup', 'source', 'sources', 'south', 'southern', 'souveniers', 'soz', 'sozi', 'sp', 'space', 'spacebucks', 'spaces', 'spageddies', 'spain', 'spam', 'spanish', 'spare', 'spares', 'spark', 'sparkling', 'spatula', 'speak', 'speaking', 'special', 'speciale', 'specialisation', 'specialise', 'specially', 'specific', 'specify', 'specs', 'speechless', 'speed', 'speedchat', 'speeding', 'speling', 'spell', 'spelled', 'spelling', 'spend', 'spending', 'spent', 'sphosting', 'spice', 'spider', 'spiffing', 'spile', 'spin', 'spinout', 'spiral', 'spirit', 'spiritual', 'spjanuary', 'spk', 'spl', 'splash', 'splashmobile', 'splat', 'splendid', 'split', 'splleing', 'spoil', 'spoiled', 'spoilt', 'spoke', 'spoken', 'sponsors', 'spontaneously', 'spook', 'spoon', 'spoons', 'sporadically', 'sport', 'sports', 'sportsx', 'spose', 'spot', 'spotty', 'spouse', 'sppok', 'spreadsheet', 'spree', 'spring', 'springs', 'sprint', 'sptv', 'spun', 'spys', 'sq825', 'squatting', 'squeeeeeze', 'squeezed', 'squid', 'squishy', 'srs', 'srsly', 'srt', 'sry', 'st', 'stability', 'stable', 'stadium', 'staff', 'stage', 'stagwood', 'stairs', 'stalk', 'stalking', 'stamped', 'stamps', 'stand', 'standard', 'standing', 'stands', 'stapati', 'star', 'starer', 'staring', 'starring', 'stars', 'starshine', 'start', 'started', 'starting', 'starts', 'starve', 'starving', 'starwars3', 'stash', 'stated', 'statement', 'statements', 'station', 'status', 'stay', 'stayed', 'stayin', 'staying', 'stays', 'std', 'stdtxtrate', 'steak', 'steal', 'stealing', 'steam', 'steamboat', 'steed', 'steering', 'step', 'steps', 'stereo', 'stereophonics', 'sterling', 'sterm', 'steve', 'stewartsize', 'steyn', 'sth', 'stick', 'sticky', 'stifled', 'stil', 'stink', 'stitch', 'stock', 'stocked', 'stockport', 'stolen', 'stomach', 'stomps', 'stone', 'stoners', 'stones', 'stool', 'stop', 'stop2', 'stop2stop', 'stopbcm', 'stopcost', 'stopcs', 'stopped', 'stops', 'stopsms', 'stoptxtstop', 'store', 'stores', 'stories', 'storming', 'story', 'str', 'str8', 'straight', 'strain', 'strange', 'stranger', 'stream', 'street', 'stress', 'stressed', 'stressful', 'stressfull', 'stretch', 'strewn', 'strict', 'strike', 'strings', 'strip', 'stripes', 'strips', 'strokes', 'strong', 'strongly', 'strt', 'strtd', 'struggling', 'sts', 'stu', 'stubborn', 'stuck', 'studdying', 'student', 'studentfinancial', 'students', 'studies', 'studio', 'study', 'studying', 'studyn', 'stuff', 'stuff42moro', 'stuffed', 'stuffing', 'stuffs', 'stunning', 'stupid', 'style', 'styles', 'styling', 'stylish', 'stylist', 'sub', 'subject', 'subletting', 'submitted', 'submitting', 'subpoly', 'subs', 'subs16', 'subscribe', 'subscribe6gbp', 'subscribed', 'subscriber', 'subscribers', 'subscription', 'subscriptions', 'subscriptn3gbp', 'subscrition', 'subsequent', 'subtoitles', 'success', 'successful', 'successfully', 'sucker', 'suckers', 'sucks', 'sudden', 'suddenly', 'sudn', 'sue', 'suffer', 'suffering', 'suffers', 'sufficient', 'sugababes', 'suganya', 'sugar', 'sugardad', 'suggest', 'suggestion', 'suggestions', 'suite', 'suite342', 'suitemates', 'suits', 'sullivan', 'sum', 'sum1', 'suman', 'sumfing', 'summer', 'summers', 'summon', 'sumthin', 'sun', 'sun0819', 'sunday', 'sundayish', 'sunlight', 'sunny', 'sunoco', 'sunroof', 'sunscreen', 'sunshine', 'suntec', 'sup', 'super', 'superb', 'superior', 'supervisor', 'suply', 'supose', 'suppliers', 'supplies', 'supply', 'support', 'supports', 'suppose', 'supposed', 'supreme', 'suprman', 'sura', 'sure', 'surely', 'surf', 'surfing', 'surgical', 'surly', 'surname', 'surprise', 'surprised', 'surrender', 'surrounded', 'survey', 'surya', 'sutra', 'sux', 'suzy', 'svc', 'sw7', 'sw73ss', 'swalpa', 'swan', 'swann', 'swap', 'swashbuckling', 'swat', 'swatch', 'sway', 'swayze', 'swear', 'sweater', 'sweatter', 'sweet', 'sweetest', 'sweetheart', 'sweetie', 'sweets', 'swell', 'swhrt', 'swimming', 'swimsuit', 'swing', 'swiss', 'switch', 'swollen', 'swoop', 'swt', 'swtheart', 'syd', 'syllabus', 'symbol', 'sympathetic', 'symptoms', 'synced', 'syria', 'syrup', 'systems', 't', 't4get2text', 't91', 'ta', 'table', 'tablet', 'tablets', 'tackle', 'tacos', 'tactful', 'tactless', 'tag', 'tagged', 'tahan', 'tai', 'tait', 'taj', 'taka', 'takecare', 'taken', 'takes', 'takin', 'taking', 'talent', 'talents', 'talk', 'talkbut', 'talked', 'talkin', 'talking', 'talks', 'tall', 'tallahassee', 'tallent', 'tamilnadu', 'tampa', 'tank', 'tantrum', 'tap', 'tape', 'tariffs', 'tarot', 'tarpon', 'taste', 'tasts', 'tat', 'tata', 'tats', 'tattoos', 'tau', 'taught', 'taunton', 'taxes', 'taxi', 'taxless', 'taxt', 'taylor', 'tayseer', 'tb', 'tbs', 'tc', 'tcr', 'tcs', 'tddnewsletter', 'te', 'tea', 'teach', 'teacher', 'teachers', 'teaches', 'teaching', 'team', 'teams', 'tear', 'tears', 'tease', 'teasing', 'tech', 'technical', 'technologies', 'tee', 'teenager', 'teeth', 'teju', 'tel', 'telediscount', 'telephone', 'telephonic', 'teletext', 'tell', 'telling', 'tellmiss', 'tells', 'telly', 'telphone', 'telugu', 'temales', 'temp', 'temper', 'temple', 'tenants', 'tendencies', 'tenerife', 'tensed', 'tension', 'teresa', 'term', 'terminated', 'terms', 'termsapply', 'ternal', 'terrible', 'terrific', 'terror', 'terrorist', 'terry', 'tescos', 'tessy', 'test', 'testing', 'tests', 'tex', 'texas', 'texd', 'text', 'text82228', 'textand', 'textbook', 'textbuddy', 'textcomp', 'texted', 'textin', 'texting', 'textoperator', 'textpod', 'texts', 'tgxxrz', 'th', 'thandiyachu', 'thangam', 'thank', 'thanks', 'thanks2', 'thanksgiving', 'thanku', 'thankyou', 'thanx', 'thanx4', 'thasa', 'that2worzels', 'thatmum', 'thats', 'the4th', 'theacusations', 'theater', 'theatre', 'thedailydraw', 'theirs', 'thekingshead', 'themed', 'themes', 'themob', 'thenampet', 'theoretically', 'theory', 'theplace', 'theres', 'thesedays', 'thesis', 'thesmszone', 'thet', 'thew', 'theyre', 'thgt', 'thia', 'thing', 'things', 'think', 'thinked', 'thinkin', 'thinking', 'thinks', 'thinkthis', 'thinl', 'thirtyeight', 'thirunelvali', 'thk', 'thkin', 'thm', 'thnk', 'thnq', 'thnx', 'tho', 'thot', 'thou', 'thought', 'thoughts', 'thousands', 'thout', 'thread', 'threats', 'threw', 'thriller', 'throat', 'throw', 'throwin', 'throwing', 'thrown', 'throws', 'ths', 'tht', 'thts', 'thuglyfe', 'thurs', 'thursday', 'thx', 'thy', 'tick', 'ticket', 'tickets', 'tie', 'tiempo', 'tiger', 'tight', 'tightly', 'tigress', 'tihs', 'tiime', 'til', 'till', 'tim', 'time', 'times', 'timi', 'timin', 'timing', 'timings', 'tip', 'tips', 'tired', 'tiring', 'tirunelvai', 'tirunelvali', 'tirupur', 'tis', 'tissco', 'title', 'titles', 'tiwary', 'tix', 'tiz', 'tke', 'tkls', 'tkts', 'tlk', 'tlp', 'tm', 'tming', 'tmorow', 'tmorrow', 'tmr', 'tmrw', 'tms', 'tmw', 'tnc', 'tncs', 'toa', 'toaday', 'tobacco', 'tobed', 'tocall', 'toclaim', 'today', 'todays', 'todo', 'tog', 'tohar', 'toilet', 'tok', 'token', 'toking', 'tol', 'told', 'toledo', 'tolerance', 'toll', 'tom', 'tomarrow', 'tomeandsaid', 'tomo', 'tomorro', 'tomorrow', 'tomorw', 'tone', 'tones', 'tones2u', 'tones2you', 'tonexs', 'tonght', 'tongued', 'tonight', 'tonights', 'tonite', 'tons', 'took', 'tookplace', 'tool', 'tooo', 'toot', 'tooth', 'toothpaste', 'tootsie', 'topic', 'toplay', 'topped', 'toppoly', 'tops', 'tor', 'torch', 'torrents', 'tortilla', 'torture', 'tosend', 'toshiba', 'toss', 'tot', 'total', 'totally', 'totes', 'touch', 'touched', 'tough', 'toughest', 'tour', 'town', 'toxic', 'toyota', 'tp', 'track', 'trackmarque', 'trade', 'traditions', 'traffic', 'train', 'trained', 'training', 'trainners', 'trains', 'tram', 'tranquility', 'transaction', 'transcribing', 'transfer', 'transfered', 'transferred', 'transfr', 'transfred', 'transport', 'trash', 'trauma', 'trav', 'travel', 'traveling', 'travelled', 'travelling', 'treacle', 'treadmill', 'treasure', 'treat', 'treated', 'treatin', 'treats', 'trebles', 'tree', 'trek', 'trends', 'trial', 'tried', 'trip', 'triple', 'trips', 'trishul', 'triumphed', 'trivia', 'tron', 'trouble', 'troubleshooting', 'trouser', 'truble', 'truck', 'true', 'true18', 'truffles', 'truly', 'truro', 'trust', 'trusting', 'truth', 'try', 'tryin', 'trying', 'ts', 'tsandcs', 'tscs', 'tscs08714740323', 'tscs087147403231winawk', 'tsunami', 'tsunamis', 'tt', 'ttyl', 'tue', 'tues', 'tuesday', 'tui', 'tuition', 'tul', 'tulip', 'tunde', 'tune', 'tunji', 'turkeys', 'turn', 'turned', 'turning', 'turns', 'tuth', 'tv', 'twat', 'twice', 'twiggs', 'twilight', 'twinks', 'twins', 'twittering', 'txt', 'txt250', 'txt43', 'txt82228', 'txtauction', 'txtin', 'txting', 'txtno', 'txts', 'txtstar', 'txtstop', 'txttowin', 'txtx', 'tyler', 'type', 'types', 'typical', 'tyrone', 'u', 'u4', 'uawake', 'ubandu', 'ubi', 'ud', 'ugadi', 'ugh', 'ugo', 'uh', 'uhhhhrmm', 'uin', 'ujhhhhhhh', 'uk', 'ukp', 'uks', 'ultimate', 'ultimately', 'ultimatum', 'um', 'umma', 'ummifying', 'ummma', 'ummmmmaah', 'unable', 'unbelievable', 'unbreakable', 'unclaimed', 'uncle', 'uncles', 'uncomfortable', 'unconditionally', 'unconscious', 'unconsciously', 'unconvinced', 'uncountable', 'uncut', 'underdtand', 'understand', 'understanding', 'understood', 'underwear', 'undrstnd', 'undrstndng', 'unemployed', 'uneventful', 'unfolds', 'unfortunately', 'unfortuntly', 'unhappiness', 'unhappy', 'uni', 'unicef', 'uniform', 'unintentional', 'unintentionally', 'unique', 'united', 'units', 'univ', 'university', 'unjalur', 'unkempt', 'unknown', 'unless', 'unlike', 'unlimited', 'unmits', 'unnecessarily', 'unni', 'unrecognized', 'unredeemed', 'unsecured', 'unsold', 'unsub', 'unsubscribe', 'unsubscribed', 'untamed', 'unusual', 'up4', 'upcharge', 'upd8', 'updat', 'update', 'upgrade', 'upgrading', 'upgrdcentre', 'upload', 'uploaded', 'upping', 'ups', 'upset', 'upstairs', 'upto', 'uptown', 'ur', 'urawinner', 'ure', 'urfeeling', 'urgent', 'urgently', 'urgh', 'urgnt', 'urgoin', 'urination', 'url', 'urmom', 'urn', 'urself', 'usa', 'usb', 'usc', 'use', 'used', 'useful', 'useless', 'user', 'uses', 'usf', 'usher', 'using', 'usmle', 'usps', 'usual', 'usually', 'uterus', 'utter', 'uttered', 'uup', 'uv', 'uve', 'uworld', 'v', 'va', 'vaazhthukkal', 'vague', 'vaguely', 'vale', 'valentine', 'valentines', 'valid', 'valid12hrs', 'valuable', 'value', 'valued', 'values', 'valuing', 'varaya', 'vargu', 'various', 'varma', 'varunnathu', 'vary', 'vasai', 'vat', 'vatian', 'vava', 'vco', 'vday', 've', 'vegas', 'vegetables', 'veggie', 'vehicle', 'velachery', 'velly', 'velusamy', 'venaam', 'venugopal', 'verified', 'verify', 'verifying', 'version', 'versus', 'vettam', 'vewy', 'vibrant', 'vibrate', 'vibrator', 'vic', 'victoria', 'victors', 'vid', 'video', 'videochat', 'videophones', 'videos', 'videosound', 'videosounds', 'view', 'vijay', 'vijaykanth', 'vikky', 'vilikkam', 'vill', 'villa', 'village', 'vinobanagar', 'violated', 'violence', 'violet', 'vip', 'vipclub4u', 'virgil', 'virgin', 'virgins', 'virtual', 'visa', 'visionsms', 'visit', 'visiting', 'visitor', 'visitors', 'vital', 'vitamin', 'viva', 'vivek', 'vl', 'voda', 'vodafone', 'vodka', 'voice', 'voicemail', 'voila', 'volcanoes', 'vomit', 'vomitin', 'vomiting', 'vote', 'voted', 'vouch4me', 'voucher', 'vouchers', 'vpod', 'vry', 'vs', 'vth', 'vu', 'w', 'w1', 'w111wx', 'w14rg', 'w1a', 'w1j', 'w1j6hl', 'w1jhl', 'w1t1jy', 'w4', 'w45wq', 'w8in', 'wa', 'wa14', 'waaaat', 'wad', 'wadebridge', 'wah', 'wahala', 'wahay', 'waheed', 'waheeda', 'wahleykkum', 'waht', 'wait', 'waited', 'waitin', 'waiting', 'wake', 'waking', 'wales', 'waliking', 'walk', 'walkabout', 'walked', 'walkin', 'walking', 'walks', 'wall', 'wallet', 'wallpaper', 'walls', 'walmart', 'walsall', 'wamma', 'wan', 'wan2', 'wana', 'wanna', 'wannatell', 'want', 'want2come', 'wanted', 'wanting', 'wants', 'wap', 'waqt', 'warm', 'warming', 'warned', 'warner', 'warning', 'warranty', 'warwick', 'washob', 'wasn', 'wasnt', 'waste', 'wasted', 'wasting', 'wat', 'watch', 'watched', 'watches', 'watchin', 'watching', 'watchng', 'water', 'watever', 'watevr', 'wating', 'watr', 'wats', 'watts', 'wave', 'wavering', 'waves', 'way', 'way2sms', 'waz', 'wc1n', 'wc1n3xx', 'weak', 'weakness', 'weaknesses', 'weapon', 'wear', 'wearing', 'weaseling', 'weasels', 'weather', 'web', 'web2mobile', 'webadres', 'webeburnin', 'webpage', 'website', 'wed', 'weddin', 'wedding', 'weddingfriend', 'wednesday', 'weds', 'wee', 'weed', 'week', 'weekdays', 'weekend', 'weekends', 'weekly', 'weeks', 'weigh', 'weighed', 'weight', 'weightloss', 'weird', 'weirdest', 'weirdo', 'weirdy', 'weiyi', 'welcome', 'welcomes', 'wellda', 'welp', 'wen', 'wendy', 'wenever', 'went', 'wenwecan', 'wer', 'werebored', 'weren', 'werethe', 'wesley', 'wesleys', 'west', 'western', 'westlife', 'westonzoyland', 'westshore', 'wet', 'wetherspoons', 'wewa', 'whassup', 'whats', 'whatsup', 'wheat', 'wheel', 'wheellock', 'whenevr', 'whens', 'whereare', 'wherevr', 'wherre', 'whilltake', 'whispers', 'white', 'whn', 'whore', 'whos', 'whr', 'wi', 'wicked', 'wicket', 'wicklow', 'wid', 'widelive', 'wif', 'wife', 'wifes', 'wifi', 'wihtuot', 'wikipedia', 'wil', 'wild', 'wildest', 'wildlife', 'willing', 'willpower', 'win', 'win150ppmx3age16', 'wind', 'window', 'windows', 'winds', 'windy', 'wine', 'wined', 'wings', 'wining', 'winner', 'winnersclub', 'winning', 'wins', 'winterstone', 'wipro', 'wire3', 'wisdom', 'wise', 'wish', 'wisheds', 'wishes', 'wishin', 'wishing', 'wishlist', 'wiskey', 'wit', 'withdraw', 'wither', 'witin', 'witot', 'witout', 'wiv', 'wizzle', 'wk', 'wkend', 'wkent', 'wkg', 'wkly', 'wknd', 'wks', 'wlcome', 'wld', 'wml', 'wn', 'wnevr', 'wnt', 'wo', 'woah', 'wocay', 'woke', 'woken', 'woman', 'womdarfull', 'women', 'won', 'wondar', 'wondarfull', 'wonder', 'wonderful', 'wondering', 'wonders', 'wont', 'woo', 'woodland', 'woods', 'woohoo', 'woot', 'woould', 'woozles', 'worc', 'word', 'words', 'work', 'workage', 'workand', 'workin', 'working', 'workout', 'works', 'world', 'worlds', 'worms', 'worried', 'worries', 'worry', 'worrying', 'worse', 'worst', 'worth', 'worthless', 'wot', 'wotu', 'wotz', 'woul', 'woulda', 'wouldn', 'wounds', 'wow', 'wrc', 'wrecked', 'wrench', 'wrenching', 'wright', 'write', 'writhing', 'wrk', 'wrkin', 'wrking', 'wrks', 'wrld', 'wrnog', 'wrong', 'wrongly', 'wrote', 'ws', 'wt', 'wtc', 'wtf', 'wth', 'wthout', 'wtlp', 'wud', 'wudn', 'wuld', 'wuldnt', 'wun', 'www', 'wylie', 'x', 'x2', 'x29', 'x49', 'xafter', 'xam', 'xavier', 'xchat', 'xclusive', 'xin', 'xmas', 'xoxo', 'xt', 'xuhui', 'xx', 'xxsp', 'xxuk', 'xxx', 'xxxmobilemovieclub', 'xxxx', 'xxxxx', 'xxxxxx', 'xxxxxxx', 'xxxxxxxx', 'xxxxxxxxxxxxxx', 'xy', 'y', 'y87', 'ya', 'yah', 'yahoo', 'yalrigu', 'yalru', 'yam', 'yan', 'yar', 'yarasu', 'yards', 'yavnt', 'yaxx', 'yaxxx', 'yay', 'yck', 'yeah', 'year', 'years', 'yeesh', 'yeh', 'yelling', 'yellow', 'yelow', 'yen', 'yeovil', 'yep', 'yer', 'yes', 'yest', 'yesterday', 'yetty', 'yetunde', 'yhl', 'yi', 'yifeng', 'yijue', 'ym', 'ymca', 'yo', 'yoga', 'yogasana', 'yor', 'yorge', 'youdoing', 'youi', 'young', 'younger', 'youphone', 'youre', 'yourinclusive', 'yourjob', 'youuuuu', 'youwanna', 'yoville', 'yowifes', 'yoyyooo', 'yr', 'yrs', 'ystrday', 'ything', 'yummmm', 'yummy', 'yun', 'yunny', 'yuo', 'yuou', 'yup', 'yupz', 'z', 'zac', 'zaher', 'zealand', 'zebra', 'zed', 'zeros', 'zhong', 'zindgi', 'zoe', 'zogtorius', 'zoom', 'zouk', 'zyada']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation\n",
    "\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train/test \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                            X, y, test_size=0.3,\n",
    "                                            random_state=23\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# train data using X_train and y_train \n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy score: 98.08612440191388\nPrecision score: 89.76744186046511\nRecall score: 95.07389162561576\nF1 score: 92.3444976076555\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy, precision, recall and f1 score\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, y_pred) *100))\n",
    "print('Precision score: {}'.format(precision_score(y_test, y_pred) * 100))\n",
    "print('Recall score: {}'.format(recall_score(y_test, y_pred) * 100))\n",
    "print('F1 score: {}'.format(f1_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1447,   22],\n",
       "       [  10,  193]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# print the confusion matrix to evaluate the accuracy of a classification.\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.967881370993974"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Compute Area Under the Receiver Operating Characteristic Curve\n",
    "# (ROC AUC)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "source": [
    " AUC measures the quality of the model's predictions irrespective of what classification threshold is chosen. \n",
    "Without doing any hyperparameters our model seems to have done very good."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Prediction\n",
    "comment = [\"Hello, how are you?\"]\n",
    "sentence = cv.transform(comment).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "clf.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {'ham': 0, 'spam': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_values([0, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "class_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ham\n"
     ]
    }
   ],
   "source": [
    "if clf.predict(sentence) == 1:\n",
    "    print(\"Spam\")\n",
    "else:\n",
    "    print(\"Ham\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/home/paul/workspace/data-science/my-projects/SMS-Spam-Classifier-App-master/ham-or-spam-nb-classifier/models/model.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "import os\n",
    "from joblib import dump, load\n",
    "# import joblib\n",
    "\n",
    "dirname = os.path.dirname('~/workspace/data-science/my-projects/SMS-Spam-Classifier-App-master/')\n",
    "\n",
    "file_name = os.path.join(dirname, 'ham-or-spam-nb-classifier/models/model.joblib')\n",
    "\n",
    "dump(clf, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and test the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model\n",
    "path = '/home/paul/workspace/data-science/my-projects/SMS-Spam-Classifier-App-master/ham-or-spam-nb-classifier/models/'\n",
    "saved_model = load(path + 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 98.09 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy and predictions\n",
    "score = saved_model.score(X_test, y_test)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))\n",
    "y_pred= saved_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# Sample Prediciton \n",
    "comment2 = [\"Hey, you have won a prize\"]\n",
    "sentence2 = cv.transform(comment2).toarray()\n",
    "saved_model.predict(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Spam\n"
     ]
    }
   ],
   "source": [
    "# example 2\n",
    "if saved_model.predict(sentence2) == 1:\n",
    "    print(\"Spam\")\n",
    "else:\n",
    "    print(\"Ham\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model seems to be working properly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd09290d09d31cd62119176a8655120c8babd6899d0f10ccd6f0fd5db15acd4ea19",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "9290d09d31cd62119176a8655120c8babd6899d0f10ccd6f0fd5db15acd4ea19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}